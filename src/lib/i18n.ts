export type Locale = "en" | "zh";

const en = {
  hero: {
    tagline: "Open Source AI Agent",
    title: "From Zero to Production\nin 48 Hours",
    subtitle:
      "Pure vibe coding — one person orchestrating AI to ship a full-stack Agent platform with 7 models, 10 tools, and 3 platforms in a single sprint.",
    cta: "Try It Live",
    ctaSource: "View Source",
    stats: { hours: "Hours", commits: "Commits", features: "Features", platforms: "Platforms" },
  },
  architecture: {
    label: "Architecture",
    title: "Seven-Layer Stack",
    layers: [
      { name: "Cross-Platform", tech: "Electron · Capacitor · Vercel", detail: "One codebase → Web + Mac + iPhone. Zero platform-specific code in business logic. Thin native shells." },
      { name: "Voice & Generative UI", tech: "Qwen3 TTS/STT · 36 Components", detail: "Push-to-talk voice I/O. AI-generated interactive UI with intent-gated zero-cost triggering." },
      { name: "Memory & Context", tech: "Dual Memory · Dual Compression", detail: "Long-term + daily logs. Client 70% proactive + server 85% safety net. Zero vector DB semantic search." },
      { name: "Tool Ecosystem", tech: "10 Built-in · MCP Protocol", detail: "Per-request tool discovery lifecycle — a serverless-first innovation. Web search, code exec, image gen, and more." },
      { name: "AI Orchestration", tech: "7 Models · 4 Providers", detail: "Kimi / DeepSeek / Gemini / MiniMax. Bidirectional fallback chain. Per-model thinking level control." },
      { name: "Backend", tech: "Serverless API · Supabase Postgres", detail: "maxDuration=300 for deep reasoning. File parsing pipeline (PDF/DOCX/XLSX/CSV). Row-Level Security." },
      { name: "Frontend", tech: "Next.js 15 · React 19 · shadcn/ui", detail: "Virtual scrolling, Error Boundary isolation, optimistic UI with debounced Supabase sync." },
    ],
  },
  features: {
    label: "Capabilities",
    title: "Core Features",
    items: [
      { title: "Multi-Model Orchestration", desc: "7 models across 4 providers with smart routing. Bidirectional fallback chain ensures zero downtime. Per-model thinking level control." },
      { title: "MCP Tool Ecosystem", desc: "10 built-in tools + Model Context Protocol for user-extensible AI capabilities. Per-request lifecycle — a serverless-first innovation." },
      { title: "Conversation Memory", desc: "Dual-layer memory with LLM-powered semantic search. Zero vector database cost — Postgres + LLM extraction replaces embeddings." },
      { title: "Voice I/O", desc: "Full-duplex voice via Qwen3 TTS/STT. Push-to-talk recognition with 3-min auto-stop. Natural voice synthesis." },
      { title: "Arena Mode", desc: "Side-by-side dual-model comparison with parallel streaming. Choose the winner — model auto-switches to the best performer." },
      { title: "Generative UI", desc: "36 interactive shadcn/ui components generated by AI. Intent-gated triggering: zero extra token cost when not needed." },
      { title: "Artifacts Panel", desc: "Live preview for code, HTML, Markdown, CSV, SVG in sandboxed iframe. Resizable panel with one-click copy or download." },
      { title: "Cross-Platform", desc: "One codebase → Web + Mac (Electron) + iPhone (Capacitor). Zero platform-specific code in src/. Thin native shells." },
    ],
  },
  timeline: {
    label: "Build Log",
    title: "48-Hour Sprint",
    sprints: [
      { time: "Day 1 AM", event: "Project init → LLM + TTS + STT connected" },
      { time: "Day 1 PM", event: "Multi-model switching, 5 tools, sidebar, settings" },
      { time: "Day 1 Night", event: "Auth system, Supabase persistence, ToolPlugin arch" },
      { time: "Day 2 AM", event: "Code execution, file parsing, Artifacts, Skills" },
      { time: "Day 2 PM", event: "Deploy tuning, Electron desktop, Capacitor iOS" },
      { time: "Sprint 2", event: "Memory system, context compression, 62 tests" },
    ],
  },
  highlights: {
    label: "Engineering",
    title: "Key Decisions",
    items: [
      { title: "Serverless MCP", desc: "Per-request tool discovery lifecycle in stateless Vercel. Create → discover → use → close in a single request." },
      { title: "Trace Merging", desc: "Shared traceId merges OpenTelemetry auto-instrumentation with Langfuse business context into unified observability." },
      { title: "Zero-Vector Search", desc: "LLM extracts relevant memories from plaintext Postgres — no vector DB, no embeddings, no extra infra cost." },
      { title: "Dual Compression", desc: "Client proactive at 70% + server safety net at 85%. Long conversations never hit context window limits." },
    ],
  },
  tech: { title: "Built With" },
  faq: {
    title: "FAQ",
    items: [
      { q: "What is Limitless Agent?", a: "An open-source, full-stack AI agent platform built from scratch in 48 hours. 7 models, 10 tools, voice I/O — running on Web, Mac, and iPhone from a single codebase." },
      { q: "How was it built?", a: "AI-assisted development (vibe coding) with Claude and Cursor. 33 commits, 37 features shipped in two sprints." },
      { q: "What makes the architecture unique?", a: "Serverless MCP tool discovery, OTel + Langfuse trace merging, zero-vector semantic search, and dual-layer context compression." },
      { q: "Is it open source?", a: "Yes — fully open source on GitHub. Fork it, customize it, deploy your own agent." },
      { q: "What skills does this demonstrate?", a: "0→1 product development, full-stack AI integration, cross-platform deployment, system design, and rapid prototyping with AI assistance." },
    ],
  },
  footer: {
    cta: "View Source Code",
    copyright: "© 2026 Limitless Agent. All rights reserved.",
    github: "GitHub",
    badge: "Built with Vibe Coding",
  },
};

const zh: typeof en = {
  hero: {
    tagline: "开源 AI Agent",
    title: "从零到生产\n48 小时",
    subtitle:
      "纯 Vibe Coding — 一个人指挥 AI，一次冲刺交付全栈 Agent 平台：7 个模型、10 个工具、3 端部署。",
    cta: "在线体验",
    ctaSource: "查看源码",
    stats: { hours: "小时", commits: "次提交", features: "个功能", platforms: "端部署" },
  },
  architecture: {
    label: "架构",
    title: "七层技术栈",
    layers: [
      { name: "跨端部署", tech: "Electron · Capacitor · Vercel", detail: "一套代码 → Web + Mac + iPhone。业务逻辑零平台特定代码，原生壳极致轻薄。" },
      { name: "语音 & 生成式 UI", tech: "Qwen3 TTS/STT · 36 组件", detail: "按住说话语音交互。AI 生成可交互 UI 组件，意图门控零成本触发。" },
      { name: "记忆 & 上下文", tech: "双层记忆 · 双层压缩", detail: "长期记忆 + 日志。客户端 70% 主动压缩 + 服务端 85% 兜底。零向量库语义搜索。" },
      { name: "工具生态", tech: "10 内置 · MCP 协议", detail: "Per-request 工具发现生命周期 — Serverless 环境下的创新方案。搜索、代码执行、图片生成等。" },
      { name: "AI 编排层", tech: "7 模型 · 4 提供商", detail: "Kimi / DeepSeek / Gemini / MiniMax。双向降级链。模型级 Thinking Level 控制。" },
      { name: "后端", tech: "Serverless API · Supabase Postgres", detail: "maxDuration=300 支持深度推理。文件解析管线（PDF/DOCX/XLSX/CSV）。行级安全策略。" },
      { name: "前端", tech: "Next.js 15 · React 19 · shadcn/ui", detail: "虚拟滚动、Error Boundary 隔离、乐观 UI + Supabase 防抖同步。" },
    ],
  },
  features: {
    label: "能力",
    title: "核心功能",
    items: [
      { title: "多模型编排", desc: "7 模型 × 4 提供商智能路由。双向降级链保障零宕机。模型级 Thinking Level 控制。" },
      { title: "MCP 工具生态", desc: "10 内置工具 + Model Context Protocol 用户扩展。Per-request 生命周期 — Serverless 创新。" },
      { title: "对话记忆", desc: "双层记忆 + LLM 驱动语义搜索。零向量库成本 — Postgres + LLM 提取替代 Embedding。" },
      { title: "语音交互", desc: "Qwen3 TTS/STT 全双工语音。按住说话即时识别，3 分钟自动截止，自然语音合成。" },
      { title: "Arena 模式", desc: "双模型并行流式对比。选出胜者后自动切换到更优模型。" },
      { title: "Generative UI", desc: "AI 生成 36 种可交互 shadcn/ui 组件。意图门控：不触发时零额外 token 消耗。" },
      { title: "Artifacts 面板", desc: "代码/HTML/Markdown/CSV/SVG 沙箱实时预览。可调面板，一键复制或下载。" },
      { title: "三端同构", desc: "一套代码 → Web + Mac(Electron) + iPhone(Capacitor)。src/ 内零平台特定代码。" },
    ],
  },
  timeline: {
    label: "开发日志",
    title: "48 小时冲刺",
    sprints: [
      { time: "第 1 天上午", event: "项目初始化 → LLM + TTS + STT 联通" },
      { time: "第 1 天下午", event: "多模型切换、5 个工具、侧边栏、设置面板" },
      { time: "第 1 天晚上", event: "Auth 认证、Supabase 持久化、ToolPlugin 架构" },
      { time: "第 2 天上午", event: "代码执行、文件解析、Artifacts、Skills 系统" },
      { time: "第 2 天下午", event: "部署调优、Electron 桌面端、Capacitor iOS" },
      { time: "第 2 轮迭代", event: "记忆系统、上下文压缩、62 个测试用例" },
    ],
  },
  highlights: {
    label: "工程决策",
    title: "关键设计",
    items: [
      { title: "Serverless MCP", desc: "无状态 Vercel 环境下的 Per-request 工具发现生命周期。单请求内 Create → Discover → Use → Close。" },
      { title: "Trace 合并", desc: "共享 traceId 将 OpenTelemetry 自动埋点与 Langfuse 业务上下文合并为统一可观测视图。" },
      { title: "零向量库搜索", desc: "LLM 从 Postgres 明文中提取相关记忆 — 无向量库、无 Embedding、无额外基础设施成本。" },
      { title: "双层压缩", desc: "客户端 70% 主动压缩 + 服务端 85% 安全兜底。长对话永不触碰上下文窗口限制。" },
    ],
  },
  tech: { title: "技术栈" },
  faq: {
    title: "常见问题",
    items: [
      { q: "Limitless Agent 是什么？", a: "一个开源全栈 AI Agent 平台，48 小时从零构建。7 个模型、10 个工具、语音交互 — 一套代码运行在 Web、Mac、iPhone 三端。" },
      { q: "怎么做到的？", a: "AI 辅助开发（Vibe Coding），使用 Claude 和 Cursor 加速。33 次提交，37 个功能两轮迭代交付。" },
      { q: "架构有什么独特之处？", a: "Serverless MCP 工具发现、OTel + Langfuse Trace 合并、零向量库语义搜索、双层上下文压缩。" },
      { q: "开源吗？", a: "完全开源，代码在 GitHub 上。Fork、定制、部署你自己的 Agent。" },
      { q: "展现了哪些能力？", a: "0→1 产品开发、全栈 AI 集成、跨端部署、系统设计、AI 辅助快速原型。" },
    ],
  },
  footer: {
    cta: "查看源码",
    copyright: "© 2026 Limitless Agent. All rights reserved.",
    github: "GitHub",
    badge: "Vibe Coding 构建",
  },
};

const dictionaries = { en, zh } as const;

export function getDictionary(locale: Locale) {
  return dictionaries[locale];
}
